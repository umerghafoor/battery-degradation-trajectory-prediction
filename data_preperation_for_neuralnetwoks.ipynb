{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865fa9a3-7cda-4cf0-a15e-a95973331a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from functions import *\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0839c57",
   "metadata": {},
   "source": [
    "# 1 Folder Data loading\n",
    "The code is loading multiple CSV files from a specified folder path and converting them into pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dbaa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/e production=ep sanyo ep sanyo 005\" \n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "dataframes = []\n",
    "dfarrnames = []\n",
    "\n",
    "dataframesCU = []\n",
    "dfarrnamesCU = []\n",
    "\n",
    "# Loop through the CSV files and load only those ending with \"Format01=Kreis 5-064\" and \"TBA_CU\"\n",
    "for csv_file in csv_files:\n",
    "    if \"Format01=Kreis\" in csv_file:\n",
    "        if \"TBA_Zyk\" in csv_file:\n",
    "            dfarr = pd.read_csv(csv_file, skiprows=[1])\n",
    "            dfarr['Zeit'] = dfarr['Zeit'].apply(convert_to_linear_time)\n",
    "            dfarr['Zeit'] = dfarr['Zeit'] - dfarr['Zeit'].iloc[0]\n",
    "            dfarr['Zeit'] = dfarr['Zeit'] / 3600\n",
    "            dataframes.append(dfarr)\n",
    "            dfarrnames.append(csv_file)\n",
    "        if \"TBA_CU\" in csv_file:\n",
    "            dfarr = pd.read_csv(csv_file, skiprows=[1])\n",
    "            dfarr['Zeit'] = dfarr['Zeit'].apply(convert_to_linear_time)\n",
    "            dfarr['Zeit'] = dfarr['Zeit'] - dfarr['Zeit'].iloc[0]\n",
    "            dfarr['Zeit'] = dfarr['Zeit'] / 3600\n",
    "            dataframesCU.append(dfarr)\n",
    "            dfarrnamesCU.append(csv_file)\n",
    "\n",
    "noFiles = 0\n",
    "for i, dfarr in enumerate(dataframes):\n",
    "    num_rows, num_columns = dfarr.shape\n",
    "    print(f\"DataFrame {i + 1} - Rows: {num_rows}, Columns: {num_columns}\")\n",
    "    noFiles += 1\n",
    "print(noFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afb0987",
   "metadata": {},
   "source": [
    "test that data is loaded succesfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de4da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_columns = dataframes[1].shape\n",
    "\n",
    "print(f\"Number of rows (length): {num_rows}\")\n",
    "print(f\"Number of columns (width): {num_columns}\")\n",
    "# dataframes[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8115467c",
   "metadata": {},
   "source": [
    "Deleting Invalid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82969f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataframes = []\n",
    "valid_dataframesCU = []\n",
    "\n",
    "for i, (df, dfCu) in enumerate(zip(dataframes, dataframesCU)):\n",
    "    # Check if the 16th column is named 'Spannung' (Python uses zero-based indexing)\n",
    "    if len(df.columns) > 15 and df.columns[15] == 'Spannung':\n",
    "        valid_dataframes.append(df)\n",
    "        valid_dataframesCU.append(dfCu)\n",
    "    else:\n",
    "        print('deleted:', i)\n",
    "\n",
    "# Update dataframes with valid dataframes\n",
    "dataframes = valid_dataframes\n",
    "dataframesCU = valid_dataframesCU\n",
    "\n",
    "noFiles = 0\n",
    "for i, dfarr in enumerate(dataframes):\n",
    "    num_rows, num_columns = dfarr.shape\n",
    "    print(f\"DataFrame {i + 1} - Rows: {num_rows}, Columns: {num_columns}\")\n",
    "    noFiles += 1\n",
    "print(noFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f863e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataframes = []\n",
    "valid_dataframesCU = []\n",
    "\n",
    "for i, (df, dfCu) in enumerate(zip(dataframes, dataframesCU)):\n",
    "    # Check if the 16th column is named 'Spannung' (Python uses zero-based indexing)\n",
    "    if len(dfCu.columns) > 15 and dfCu.columns[15] == 'Spannung':\n",
    "        valid_dataframes.append(df)\n",
    "        valid_dataframesCU.append(dfCu)\n",
    "    else:\n",
    "        print('deleted:', i)\n",
    "\n",
    "# Update dataframes with valid dataframes\n",
    "dataframes = valid_dataframes\n",
    "dataframesCU = valid_dataframesCU\n",
    "\n",
    "noFiles = 0\n",
    "for i, dfarr in enumerate(dataframes):\n",
    "    num_rows, num_columns = dfarr.shape\n",
    "    print(f\"DataFrame {i + 1} - Rows: {num_rows}, Columns: {num_columns}\")\n",
    "    noFiles += 1\n",
    "print(noFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dataframes:\n",
    "    print(df.shape)\n",
    "for df in dataframesCU:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0e2521",
   "metadata": {},
   "source": [
    "### Extracting capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b827506",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataframes = []\n",
    "\n",
    "for df in dataframesCU:\n",
    "    schritt_mask = ((df['Schritt'] == 4) | (df['Schritt'] == 5)) & (df['Zeit'] >= 10)\n",
    "    start_index = df[schritt_mask]\n",
    "    start_time = start_index.iloc[0]['Zeit']\n",
    "    end_time = start_time + 4\n",
    "    print(start_index.iloc[0]['Zeit'])\n",
    "\n",
    "    time_mask = (df['Zeit'] >= start_time) & (df['Zeit'] <= end_time) & ((df['Schritt'] == 4) | (df['Schritt'] == 5))\n",
    "\n",
    "    filtered_df = df[time_mask]\n",
    "    filtered_dataframes.append(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce443081",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_extract = [9]\n",
    "\n",
    "max_values_list = []\n",
    "min_values_list = []\n",
    "capacity_values_list = []\n",
    "iteration_range = range(len(dataframes))\n",
    "\n",
    "for df in filtered_dataframes:\n",
    "    max_values = max_threshold(columns_to_extract, df, 0, 35)\n",
    "    min_values = min_threshold(columns_to_extract, df, 0, 35)\n",
    "    \n",
    "    max_values_list .append(max_values)\n",
    "    min_values_list.append(min_values)\n",
    "    capacity = max_values[0]-min_values[0]\n",
    "    capacity_values_list.append(capacity)\n",
    "\n",
    "print(max_values_list)\n",
    "print(min_values_list)\n",
    "print(capacity_values_list)\n",
    "print(iteration_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_indices = []\n",
    "\n",
    "extracted_capacity_values = [value for i, value in enumerate(capacity_values_list) if i not in skip_indices]\n",
    "\n",
    "iteration_range = range(len(extracted_capacity_values))\n",
    "\n",
    "print(extracted_capacity_values)\n",
    "print(iteration_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098649cc",
   "metadata": {},
   "source": [
    "### Crop The Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea765d20",
   "metadata": {},
   "source": [
    "\n",
    "This script iterates through a list of dataframes and performs the following operations:\n",
    "\n",
    "1. Seprate the data farame of each cycle or `Zyklus`.\n",
    "2. Extracts a subset of the filtered dataframe from `3.65-3.85`.\n",
    "3. Filters the subset based on the `Spannung` column values.\n",
    "4. Calculates the maximum and minimum values of `AhAkku` column in the filtered dataframe.\n",
    "5. Interpolates 50 values for `AhAkku` column.\n",
    "6. Writes the interpolated values along with the difference between maximum and minimum `AhAkku` values to a CSV file.\n",
    "\n",
    "CSV File Format:\n",
    "- Each row corresponds to a set of interpolated values along with the difference between max and min AhAkku values.\n",
    "- The columns represent the interpolated values (Interpolated_1 to 'Interpolated_50') followed by `Max_Min_Ahakku_Difference`.\n",
    "\n",
    "Note: Ensure that the 'dataframes' variable is a list containing pandas DataFrames.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285f2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temptest.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # writer.writerow(['Interpolated_1', 'Interpolated_2', ..., 'Interpolated_50', 'Max_Min_Ahakku_Difference'])\n",
    "\n",
    "    I = 0\n",
    "    for i, df in enumerate(dataframes):\n",
    "        filtered_df = df[(df['Zyklus'] == 1)]\n",
    "        quarter_len = len(filtered_df) // 4\n",
    "        filtered_df = filtered_df.iloc[quarter_len:]\n",
    "\n",
    "        filtered_df_ahakku = filtered_df[(filtered_df['Spannung'] >= 3.65) & (filtered_df['Spannung'] <= 3.85)]\n",
    "\n",
    "        ahakku_values = filtered_df_ahakku['AhAkku'].values\n",
    "        \n",
    "        if len(ahakku_values) > 0:\n",
    "            # Interpolate 50 values\n",
    "            interpolated_values = np.interp(np.linspace(0, len(ahakku_values) - 1, 50), np.arange(len(ahakku_values)), ahakku_values)\n",
    "\n",
    "            writer.writerow(list(interpolated_values) + [extracted_capacity_values[I]])\n",
    "\n",
    "        I += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca291c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = [15,9] \n",
    "#plotAllDates(dataframes[0],columns_to_plot)\n",
    "I = 0\n",
    "for i in dataframes:\n",
    "    #print(\"Graph No. :\",I)\n",
    "    # print(I,' :',dfarrnames[I])\n",
    "    plot(columns_to_plot,dataframesCU[I])\n",
    "    # plot_threshold(columns_to_plot, dataframes[I], 0, 2)\n",
    "    I=I+1\n",
    "\n",
    "# 4,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e8ea54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/e production=ep sanyo ep sanyo 00\n",
      "data/e production=ep sanyo ep sanyo 01\n",
      "data/e production=ep sanyo ep sanyo 02\n",
      "data/e production=ep sanyo ep sanyo 03\n",
      "data/e production=ep sanyo ep sanyo 04\n",
      "data/e production=ep sanyo ep sanyo 05\n",
      "data/e production=ep sanyo ep sanyo 06\n",
      "data/e production=ep sanyo ep sanyo 07\n",
      "data/e production=ep sanyo ep sanyo 08\n",
      "data/e production=ep sanyo ep sanyo 09\n",
      "data/e production=ep sanyo ep sanyo 010\n",
      "deleted: 14\n",
      "deleted: 9\n",
      "data/e production=ep sanyo ep sanyo 011\n",
      "deleted: 4\n",
      "deleted: 8\n",
      "data/e production=ep sanyo ep sanyo 012\n",
      "data/e production=ep sanyo ep sanyo 013\n",
      "deleted: 1\n",
      "deleted: 7\n",
      "data/e production=ep sanyo ep sanyo 014\n",
      "deleted: 10\n",
      "data/e production=ep sanyo ep sanyo 015\n",
      "deleted: 4\n",
      "deleted: 8\n",
      "data/e production=ep sanyo ep sanyo 016\n",
      "deleted: 5\n",
      "data/e production=ep sanyo ep sanyo 017\n",
      "deleted: 6\n",
      "deleted: 5\n",
      "deleted: 12\n",
      "data/e production=ep sanyo ep sanyo 018\n",
      "deleted: 2\n",
      "data/e production=ep sanyo ep sanyo 019\n",
      "deleted: 7\n",
      "deleted: 9\n",
      "deleted: 2\n",
      "data/e production=ep sanyo ep sanyo 020\n",
      "data/e production=ep sanyo ep sanyo 021\n",
      "deleted: 3\n",
      "deleted: 11\n",
      "data/e production=ep sanyo ep sanyo 022\n",
      "deleted: 14\n",
      "data/e production=ep sanyo ep sanyo 023\n",
      "deleted: 7\n",
      "data/e production=ep sanyo ep sanyo 024\n",
      "data/e production=ep sanyo ep sanyo 025\n",
      "data/e production=ep sanyo ep sanyo 026\n",
      "deleted: 0\n",
      "deleted: 2\n",
      "data/e production=ep sanyo ep sanyo 027\n",
      "data/e production=ep sanyo ep sanyo 028\n",
      "deleted: 12\n",
      "data/e production=ep sanyo ep sanyo 029\n",
      "deleted: 1\n",
      "deleted: 9\n",
      "data/e production=ep sanyo ep sanyo 030\n",
      "data/e production=ep sanyo ep sanyo 031\n",
      "deleted: 3\n",
      "deleted: 4\n",
      "data/e production=ep sanyo ep sanyo 032\n",
      "deleted: 5\n",
      "data/e production=ep sanyo ep sanyo 033\n",
      "data/e production=ep sanyo ep sanyo 034\n",
      "deleted: 0\n",
      "data/e production=ep sanyo ep sanyo 035\n",
      "deleted: 5\n",
      "deleted: 14\n",
      "data/e production=ep sanyo ep sanyo 036\n",
      "deleted: 10\n",
      "data/e production=ep sanyo ep sanyo 037\n",
      "data/e production=ep sanyo ep sanyo 038\n",
      "deleted: 1\n",
      "deleted: 2\n",
      "data/e production=ep sanyo ep sanyo 039\n",
      "data/e production=ep sanyo ep sanyo 040\n",
      "deleted: 12\n",
      "data/e production=ep sanyo ep sanyo 041\n",
      "deleted: 4\n",
      "deleted: 8\n",
      "data/e production=ep sanyo ep sanyo 042\n",
      "deleted: 0\n",
      "deleted: 9\n",
      "data/e production=ep sanyo ep sanyo 043\n",
      "data/e production=ep sanyo ep sanyo 044\n",
      "deleted: 0\n",
      "deleted: 1\n",
      "data/e production=ep sanyo ep sanyo 045\n",
      "data/e production=ep sanyo ep sanyo 046\n",
      "deleted: 4\n",
      "deleted: 5\n",
      "data/e production=ep sanyo ep sanyo 047\n",
      "deleted: 14\n",
      "data/e production=ep sanyo ep sanyo 048\n",
      "deleted: 5\n",
      "deleted: 9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from functions import *\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for i in range(49):\n",
    "\n",
    "    folder_path = \"data/e production=ep sanyo ep sanyo 0\"+ str(i)\n",
    "    print(folder_path) \n",
    "    csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "    dataframes = []\n",
    "    dfarrnames = []\n",
    "\n",
    "    dataframesCU = []\n",
    "    dfarrnamesCU = []\n",
    "\n",
    "    # Loop through the CSV files and load only those ending with \"Format01=Kreis 5-064\" and \"TBA_CU\"\n",
    "    for csv_file in csv_files:\n",
    "        if \"Format01=Kreis\" in csv_file:\n",
    "            if \"TBA_Zyk\" in csv_file:\n",
    "                dfarr = pd.read_csv(csv_file, skiprows=[1])\n",
    "                dfarr['Zeit'] = dfarr['Zeit'].apply(convert_to_linear_time)\n",
    "                dfarr['Zeit'] = dfarr['Zeit'] - dfarr['Zeit'].iloc[0]\n",
    "                dfarr['Zeit'] = dfarr['Zeit'] / 3600\n",
    "                dataframes.append(dfarr)\n",
    "                dfarrnames.append(csv_file)\n",
    "            if \"TBA_CU\" in csv_file:\n",
    "                dfarr = pd.read_csv(csv_file, skiprows=[1])\n",
    "                dfarr['Zeit'] = dfarr['Zeit'].apply(convert_to_linear_time)\n",
    "                dfarr['Zeit'] = dfarr['Zeit'] - dfarr['Zeit'].iloc[0]\n",
    "                dfarr['Zeit'] = dfarr['Zeit'] / 3600\n",
    "                dataframesCU.append(dfarr)\n",
    "                dfarrnamesCU.append(csv_file)\n",
    "\n",
    "\n",
    "    valid_dataframes = []\n",
    "    valid_dataframesCU = []\n",
    "\n",
    "    for i, (df, dfCu) in enumerate(zip(dataframes, dataframesCU)):\n",
    "        # Check if the 16th column is named 'Spannung' (Python uses zero-based indexing)\n",
    "        if len(df.columns) > 15 and df.columns[15] == 'Spannung':\n",
    "            valid_dataframes.append(df)\n",
    "            valid_dataframesCU.append(dfCu)\n",
    "        else:\n",
    "            print('deleted:', i)\n",
    "\n",
    "    # Update dataframes with valid dataframes\n",
    "    dataframes = valid_dataframes\n",
    "    dataframesCU = valid_dataframesCU\n",
    "\n",
    "\n",
    "    valid_dataframes = []\n",
    "    valid_dataframesCU = []\n",
    "\n",
    "    for i, (df, dfCu) in enumerate(zip(dataframes, dataframesCU)):\n",
    "        # Check if the 16th column is named 'Spannung' (Python uses zero-based indexing)\n",
    "        if len(dfCu.columns) > 15 and dfCu.columns[15] == 'Spannung':\n",
    "            valid_dataframes.append(df)\n",
    "            valid_dataframesCU.append(dfCu)\n",
    "        else:\n",
    "            print('deleted:', i)\n",
    "\n",
    "    # Update dataframes with valid dataframes\n",
    "    dataframes = valid_dataframes\n",
    "    dataframesCU = valid_dataframesCU\n",
    "\n",
    "    filtered_dataframes = []\n",
    "\n",
    "    for df in dataframesCU:\n",
    "        schritt_mask = ((df['Schritt'] == 4) | (df['Schritt'] == 5)) & (df['Zeit'] >= 10)\n",
    "        start_index = df[schritt_mask]\n",
    "        start_time = start_index.iloc[0]['Zeit']\n",
    "        end_time = start_time + 4\n",
    "\n",
    "        time_mask = (df['Zeit'] >= start_time) & (df['Zeit'] <= end_time) & ((df['Schritt'] == 4) | (df['Schritt'] == 5))\n",
    "\n",
    "        filtered_df = df[time_mask]\n",
    "        filtered_dataframes.append(filtered_df)\n",
    "\n",
    "    columns_to_extract = [9]\n",
    "\n",
    "    max_values_list = []\n",
    "    min_values_list = []\n",
    "    capacity_values_list = []\n",
    "    iteration_range = range(len(dataframes))\n",
    "\n",
    "    for df in filtered_dataframes:\n",
    "        max_values = max_threshold(columns_to_extract, df, 0, 35)\n",
    "        min_values = min_threshold(columns_to_extract, df, 0, 35)\n",
    "        \n",
    "        max_values_list .append(max_values)\n",
    "        min_values_list.append(min_values)\n",
    "        capacity = max_values[0]-min_values[0]\n",
    "        capacity_values_list.append(capacity)\n",
    "\n",
    "    skip_indices = []\n",
    "\n",
    "    extracted_capacity_values = [value for i, value in enumerate(capacity_values_list) if i not in skip_indices]\n",
    "\n",
    "    iteration_range = range(len(extracted_capacity_values))\n",
    "\n",
    "    with open('input(50)=3.2-3.6 ahakku , output(1)=4.2 ahakku train.csv', 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        I = 0\n",
    "        for i, df in enumerate(dataframes):\n",
    "            filtered_df = df[(df['Zyklus'] == 1)]\n",
    "            quarter_len = len(filtered_df) // 4\n",
    "            filtered_df = filtered_df.iloc[quarter_len:]\n",
    "\n",
    "            filtered_df_ahakku = filtered_df[(filtered_df['Spannung'] >= 3.65) & (filtered_df['Spannung'] <= 3.85)]\n",
    "\n",
    "            ahakku_values = filtered_df_ahakku['AhAkku'].values\n",
    "            \n",
    "            if len(ahakku_values) > 0:\n",
    "                # Interpolate 50 values\n",
    "                interpolated_values = np.interp(np.linspace(0, len(ahakku_values) - 1, 50), np.arange(len(ahakku_values)), ahakku_values)\n",
    "\n",
    "                writer.writerow(list(interpolated_values) + [extracted_capacity_values[I]])\n",
    "\n",
    "            I += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a7e58c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
